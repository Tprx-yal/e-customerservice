from langchain.chat_models import init_chat_model
from langchain_core.messages import AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents.middleware import AgentMiddleware, hook_config
from pydantic import BaseModel, Field
from typing import Literal, Dict, Any, Optional
from lg.lg_test.kg_neo4j_conn_test import get_neo4j_graph
from lg.lg_states import AgentState
from lg.lg_prompts import GUARDRAILS_SYSTEM_PROMPT
from lg.sub_lg_graphrag.agentic_rag.components.utils.utils import retrieve_and_parse_schema_from_graph_for_prompts


class AdditionalGuardrailsOutput(BaseModel):
    """
    æ ¼å¼åŒ–è¾“å‡ºï¼Œç”¨äºåˆ¤æ–­ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦ä¸å›¾è°±å†…å®¹ç›¸å…³
    """
    decision: Literal["end", "continue"] = Field(
        description="Decision on whether the question is related to the graph contents."
    )

class SafetyGuardrail(AgentMiddleware):
    """
    [é˜¶æ®µ 1: before_agent & before_model] RBAC æƒé™æ§åˆ¶ä¸­é—´ä»¶
    åœ¨æ‰§è¡Œä»»ä½•æ“ä½œå‰éªŒè¯ç”¨æˆ·æƒé™
    """

    def __init__(self):
        super().__init__()
        # å®šä¹‰ç”µå•†ç»è¥èŒƒå›´
        self.scope_description = """
        ä¸ªäººç”µå•†ç»è¥èŒƒå›´ï¼šæ™ºèƒ½å®¶å±…äº§å“ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
        - æ™ºèƒ½ç…§æ˜ï¼ˆç¯æ³¡ã€ç¯å¸¦ã€å¼€å…³ï¼‰
        - æ™ºèƒ½å®‰é˜²ï¼ˆæ‘„åƒå¤´ã€é—¨é”ã€ä¼ æ„Ÿå™¨ï¼‰
        - æ™ºèƒ½æ§åˆ¶ï¼ˆæ¸©æ§å™¨ã€é¥æ§å™¨ã€é›†çº¿å™¨ï¼‰
        - æ™ºèƒ½éŸ³ç®±ï¼ˆè¯­éŸ³åŠ©æ‰‹ã€éŸ³å“ï¼‰
        - æ™ºèƒ½å¨ç”µï¼ˆç”µé¥­ç…²ã€å†°ç®±ã€æ´—ç¢—æœºï¼‰
        - æ™ºèƒ½æ¸…æ´ï¼ˆæ‰«åœ°æœºå™¨äººã€æ´—è¡£æœºï¼‰
        
        ä¸åŒ…å«ï¼šæœè£…ã€é‹ç±»ã€ä½“è‚²ç”¨å“ã€åŒ–å¦†å“ã€é£Ÿå“ç­‰éæ™ºèƒ½å®¶å±…äº§å“ã€‚
        """
        self.model = init_chat_model(
            model="deepseek-chat",
            api_key='sk-c6a046d027964a88b8a071758f3dfca2',
            base_url="https://api.deepseek.com",
        ).with_structured_output(AdditionalGuardrailsOutput)
        self.prompt = self._get_prompt()

    def _get_prompt(self) -> ChatPromptTemplate:
        try:
            neo4j_graph = get_neo4j_graph()
        except Exception as e:
            # logger.error(f"failed to get Neo4j graph database connection: {e}")
            raise e

        scope_context = (
            f"å‚è€ƒæ­¤èŒƒå›´æè¿°æ¥å†³ç­–:\n{self.scope_description}"
            if self.scope_description is not None
            else ""
        )

        # åŠ¨æ€ä» Neo4j å›¾è¡¨ä¸­è·å–å›¾è¡¨ç»“æ„
        graph_context = (
            f"\nå‚è€ƒå›¾è¡¨ç»“æ„æ¥å›ç­”:\n{retrieve_and_parse_schema_from_graph_for_prompts(neo4j_graph)}" # type: ignore
            if neo4j_graph is not None # type: ignore
            else ""
        )
        # print(graph_context)
        # exit()
        message = scope_context + graph_context + "\nQuestion: {question}"
        full_system_prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    GUARDRAILS_SYSTEM_PROMPT,
                ),
                (
                    "human",
                    (message),
                ),
            ]
        )
        return full_system_prompt

    @hook_config(can_jump_to=["end"])  # å…è®¸åœ¨ before_agent é˜¶æ®µè·³è½¬åˆ° end
    async def abefore_agent(self, state: Dict[str, Any], runtime) -> Optional[Dict[str, Any]]: # type: ignore
        # æ„å»ºæ ¼å¼åŒ–è¾“å‡ºçš„ Chainï¼Œ å¦‚æœåŒ¹é…ï¼Œè¿”å› continueï¼Œå¦åˆ™è¿”å› end
        
        guardrails_chain = self.prompt | self.model
        guardrails_output = await guardrails_chain.ainvoke(
            {"question": state["messages"][-1].content if state["messages"] else ""}
        )
        # æ ¹æ®æ ¼å¼åŒ–è¾“å‡ºçš„ç»“æœï¼Œè¿”å›ä¸åŒçš„å“åº”
        if guardrails_output.decision == "end": # type: ignore
            # logger.info("-----Fail to pass guardrails check-----")
            return {"messages": [AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘å®¶æš‚æ—¶æ²¡æœ‰è¿™æ–¹é¢çš„å•†å“ï¼Œå¯ä»¥åœ¨åˆ«å®¶çœ‹çœ‹å“¦~")], "jump_to": "end"}
        else:
            return None

            

    # def before_model(self, state: AgentState, runtime) -> Optional[Dict[str, Any]]:
    #     """åœ¨ before_model é˜¶æ®µæ³¨å…¥ç”¨æˆ·ä¿¡æ¯åˆ° state"""
    #     try:
    #         # ä» runtime è·å–ç”¨æˆ·ä¿¡æ¯
    #         current_user = self._get_user_from_runtime(runtime)

    #         # è·å–ç”¨æˆ·è§’è‰²çš„æƒé™åˆ—è¡¨
    #         user_permissions = ROLE_PERMISSIONS.get(current_user['role'], [])

    #         log_with_timestamp(
    #             f"   ğŸ“ æ³¨å…¥ç”¨æˆ·ä¿¡æ¯åˆ° state - "
    #             f"ç”¨æˆ·: {current_user['username']}, "
    #             f"è§’è‰²: {current_user['role'].value}"
    #         )

    #         # å°†ç”¨æˆ·ä¿¡æ¯æ³¨å…¥åˆ° state
    #         return {
    #             "user_info": current_user,
    #             "user_permissions": [p.value for p in user_permissions]
    #         }
    #     except Exception as e:
    #         log_with_timestamp(f"   âŒ ç”¨æˆ·ä¿¡æ¯æ³¨å…¥å¼‚å¸¸: {str(e)}", "ERROR")
    #         return None